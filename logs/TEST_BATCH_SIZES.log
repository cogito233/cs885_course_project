nohup: ignoring input
[10:18:24] ======================================================================
[10:18:24] 测试不同Batch Size的影响
[10:18:24] 5轮对话 × 50条轨迹 × 不同Batch Size
[10:18:24] ======================================================================
[10:18:24] [1/3] 加载配置和数据...
[10:18:24] ✓ 加载了 50 条轨迹
[10:18:24]   每条约 48 步
[10:18:24] 
[2/3] 加载模型到GPU 2...
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2025-11-25 10:18:34] WARNING server_args.py:1213: Attention backend not explicitly specified. Use fa3 backend by default.
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Loading safetensors checkpoint shards:   0% Completed | 0/8 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  12% Completed | 1/8 [00:00<00:03,  1.83it/s]
Loading safetensors checkpoint shards:  25% Completed | 2/8 [00:01<00:03,  1.67it/s]
Loading safetensors checkpoint shards:  38% Completed | 3/8 [00:01<00:03,  1.66it/s]
Loading safetensors checkpoint shards:  50% Completed | 4/8 [00:02<00:02,  1.65it/s]
Loading safetensors checkpoint shards:  62% Completed | 5/8 [00:02<00:01,  1.67it/s]
Loading safetensors checkpoint shards:  75% Completed | 6/8 [00:03<00:01,  1.69it/s]
Loading safetensors checkpoint shards:  88% Completed | 7/8 [00:04<00:00,  1.70it/s]
Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:04<00:00,  2.02it/s]
Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:04<00:00,  1.80it/s]

  0%|          | 0/36 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=108.17 GB):   0%|          | 0/36 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=108.17 GB):   3%|▎         | 1/36 [00:00<00:07,  4.94it/s]Capturing batches (bs=248 avail_mem=108.02 GB):   3%|▎         | 1/36 [00:00<00:07,  4.94it/s]Capturing batches (bs=240 avail_mem=108.00 GB):   3%|▎         | 1/36 [00:00<00:07,  4.94it/s]Capturing batches (bs=240 avail_mem=108.00 GB):   8%|▊         | 3/36 [00:00<00:03,  9.82it/s]Capturing batches (bs=232 avail_mem=107.98 GB):   8%|▊         | 3/36 [00:00<00:03,  9.82it/s]Capturing batches (bs=224 avail_mem=107.96 GB):   8%|▊         | 3/36 [00:00<00:03,  9.82it/s]Capturing batches (bs=224 avail_mem=107.96 GB):  14%|█▍        | 5/36 [00:00<00:02, 11.55it/s]Capturing batches (bs=216 avail_mem=107.94 GB):  14%|█▍        | 5/36 [00:00<00:02, 11.55it/s]Capturing batches (bs=208 avail_mem=107.93 GB):  14%|█▍        | 5/36 [00:00<00:02, 11.55it/s]Capturing batches (bs=208 avail_mem=107.93 GB):  19%|█▉        | 7/36 [00:00<00:02, 12.52it/s]Capturing batches (bs=200 avail_mem=107.91 GB):  19%|█▉        | 7/36 [00:00<00:02, 12.52it/s]Capturing batches (bs=192 avail_mem=107.89 GB):  19%|█▉        | 7/36 [00:00<00:02, 12.52it/s]Capturing batches (bs=192 avail_mem=107.89 GB):  25%|██▌       | 9/36 [00:00<00:02, 13.19it/s]Capturing batches (bs=184 avail_mem=107.88 GB):  25%|██▌       | 9/36 [00:00<00:02, 13.19it/s]Capturing batches (bs=176 avail_mem=107.87 GB):  25%|██▌       | 9/36 [00:00<00:02, 13.19it/s]Capturing batches (bs=176 avail_mem=107.87 GB):  31%|███       | 11/36 [00:00<00:01, 13.41it/s]Capturing batches (bs=168 avail_mem=107.87 GB):  31%|███       | 11/36 [00:00<00:01, 13.41it/s]Capturing batches (bs=160 avail_mem=107.85 GB):  31%|███       | 11/36 [00:01<00:01, 13.41it/s]Capturing batches (bs=160 avail_mem=107.85 GB):  36%|███▌      | 13/36 [00:01<00:04,  5.68it/s]Capturing batches (bs=152 avail_mem=107.84 GB):  36%|███▌      | 13/36 [00:01<00:04,  5.68it/s]Capturing batches (bs=144 avail_mem=107.82 GB):  36%|███▌      | 13/36 [00:01<00:04,  5.68it/s]Capturing batches (bs=144 avail_mem=107.82 GB):  42%|████▏     | 15/36 [00:01<00:02,  7.03it/s]Capturing batches (bs=136 avail_mem=107.82 GB):  42%|████▏     | 15/36 [00:01<00:02,  7.03it/s]Capturing batches (bs=128 avail_mem=107.80 GB):  42%|████▏     | 15/36 [00:01<00:02,  7.03it/s]Capturing batches (bs=128 avail_mem=107.80 GB):  47%|████▋     | 17/36 [00:01<00:02,  8.37it/s]Capturing batches (bs=120 avail_mem=107.79 GB):  47%|████▋     | 17/36 [00:01<00:02,  8.37it/s]Capturing batches (bs=112 avail_mem=107.78 GB):  47%|████▋     | 17/36 [00:02<00:02,  8.37it/s]Capturing batches (bs=112 avail_mem=107.78 GB):  53%|█████▎    | 19/36 [00:02<00:01,  9.73it/s]Capturing batches (bs=104 avail_mem=107.77 GB):  53%|█████▎    | 19/36 [00:02<00:01,  9.73it/s]Capturing batches (bs=96 avail_mem=107.77 GB):  53%|█████▎    | 19/36 [00:02<00:01,  9.73it/s] Capturing batches (bs=96 avail_mem=107.77 GB):  58%|█████▊    | 21/36 [00:02<00:01, 10.81it/s]Capturing batches (bs=88 avail_mem=107.75 GB):  58%|█████▊    | 21/36 [00:02<00:01, 10.81it/s]Capturing batches (bs=80 avail_mem=107.75 GB):  58%|█████▊    | 21/36 [00:02<00:01, 10.81it/s]Capturing batches (bs=80 avail_mem=107.75 GB):  64%|██████▍   | 23/36 [00:02<00:01, 11.68it/s]Capturing batches (bs=72 avail_mem=107.74 GB):  64%|██████▍   | 23/36 [00:02<00:01, 11.68it/s]Capturing batches (bs=64 avail_mem=107.73 GB):  64%|██████▍   | 23/36 [00:02<00:01, 11.68it/s]Capturing batches (bs=64 avail_mem=107.73 GB):  69%|██████▉   | 25/36 [00:02<00:00, 12.46it/s]Capturing batches (bs=56 avail_mem=107.73 GB):  69%|██████▉   | 25/36 [00:02<00:00, 12.46it/s]Capturing batches (bs=48 avail_mem=107.72 GB):  69%|██████▉   | 25/36 [00:02<00:00, 12.46it/s]Capturing batches (bs=48 avail_mem=107.72 GB):  75%|███████▌  | 27/36 [00:02<00:00, 13.15it/s]Capturing batches (bs=40 avail_mem=107.71 GB):  75%|███████▌  | 27/36 [00:02<00:00, 13.15it/s]Capturing batches (bs=32 avail_mem=107.70 GB):  75%|███████▌  | 27/36 [00:02<00:00, 13.15it/s]Capturing batches (bs=32 avail_mem=107.70 GB):  81%|████████  | 29/36 [00:02<00:00, 13.64it/s]Capturing batches (bs=24 avail_mem=107.69 GB):  81%|████████  | 29/36 [00:02<00:00, 13.64it/s]Capturing batches (bs=16 avail_mem=107.68 GB):  81%|████████  | 29/36 [00:02<00:00, 13.64it/s]Capturing batches (bs=16 avail_mem=107.68 GB):  86%|████████▌ | 31/36 [00:02<00:00, 12.95it/s]Capturing batches (bs=12 avail_mem=107.68 GB):  86%|████████▌ | 31/36 [00:02<00:00, 12.95it/s]Capturing batches (bs=8 avail_mem=107.67 GB):  86%|████████▌ | 31/36 [00:02<00:00, 12.95it/s] Capturing batches (bs=8 avail_mem=107.67 GB):  92%|█████████▏| 33/36 [00:03<00:00, 13.67it/s]Capturing batches (bs=4 avail_mem=107.66 GB):  92%|█████████▏| 33/36 [00:03<00:00, 13.67it/s]Capturing batches (bs=2 avail_mem=107.66 GB):  92%|█████████▏| 33/36 [00:03<00:00, 13.67it/s]Capturing batches (bs=2 avail_mem=107.66 GB):  97%|█████████▋| 35/36 [00:03<00:00, 14.64it/s]Capturing batches (bs=1 avail_mem=107.65 GB):  97%|█████████▋| 35/36 [00:03<00:00, 14.64it/s]Capturing batches (bs=1 avail_mem=107.65 GB): 100%|██████████| 36/36 [00:03<00:00, 11.16it/s]
Exception in thread Thread-2 (_wait_and_warmup):
Traceback (most recent call last):
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
    self.run()
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/srt/entrypoints/http_server.py", line 1594, in _wait_and_warmup
    pipe_finish_writer.send("ready")
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py", line 427, in _send_bytes
    self._send(header + buf)
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py", line 384, in _send
    n = write(self._handle, buf)
        ^^^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
