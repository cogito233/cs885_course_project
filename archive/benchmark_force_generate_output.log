/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2025-11-25 08:41:59] INFO model_config.py:885: Downcasting torch.float32 to torch.float16.
[2025-11-25 08:41:59] WARNING server_args.py:1213: Attention backend not explicitly specified. Use fa3 backend by default.
======================================================================
批量处理性能测试 - 强制Generate版本
每一轮assistant都强制generate
======================================================================
测试时间: 2025-11-25 08:41:49

[GPU检查]
CUDA_VISIBLE_DEVICES: 3
PyTorch可见GPU数量: 1
当前使用的GPU: 0
GPU名称: NVIDIA H200

[1/5] 加载配置文件...
✓ 配置加载完成

[2/5] 加载轨迹数据...
✓ 加载了 50 条轨迹
  原始数据平均约 48 步/轨迹

[3/5] 正在加载模型到GPU 3...
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:01<00:09,  1.57s/it]
Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:03<00:08,  1.60s/it]
Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:04<00:06,  1.62s/it]
Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:06<00:04,  1.62s/it]
Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:08<00:03,  1.64s/it]
Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:09<00:01,  1.50s/it]
Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:10<00:00,  1.26s/it]
Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:10<00:00,  1.45s/it]

  0%|          | 0/36 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=33.91 GB):   0%|          | 0/36 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=33.91 GB):   3%|▎         | 1/36 [00:00<00:04,  8.74it/s]Capturing batches (bs=248 avail_mem=33.75 GB):   3%|▎         | 1/36 [00:00<00:04,  8.74it/s]Capturing batches (bs=240 avail_mem=33.74 GB):   3%|▎         | 1/36 [00:00<00:04,  8.74it/s]Capturing batches (bs=232 avail_mem=33.73 GB):   3%|▎         | 1/36 [00:00<00:04,  8.74it/s]Capturing batches (bs=232 avail_mem=33.73 GB):  11%|█         | 4/36 [00:00<00:01, 17.58it/s]Capturing batches (bs=224 avail_mem=33.72 GB):  11%|█         | 4/36 [00:00<00:01, 17.58it/s]Capturing batches (bs=216 avail_mem=33.72 GB):  11%|█         | 4/36 [00:00<00:01, 17.58it/s]Capturing batches (bs=208 avail_mem=33.71 GB):  11%|█         | 4/36 [00:00<00:01, 17.58it/s]Capturing batches (bs=208 avail_mem=33.71 GB):  19%|█▉        | 7/36 [00:00<00:01, 19.56it/s]Capturing batches (bs=200 avail_mem=33.70 GB):  19%|█▉        | 7/36 [00:00<00:01, 19.56it/s]Capturing batches (bs=192 avail_mem=33.69 GB):  19%|█▉        | 7/36 [00:00<00:01, 19.56it/s]Capturing batches (bs=184 avail_mem=33.69 GB):  19%|█▉        | 7/36 [00:00<00:01, 19.56it/s]Capturing batches (bs=184 avail_mem=33.69 GB):  28%|██▊       | 10/36 [00:00<00:01, 20.64it/s]Capturing batches (bs=176 avail_mem=33.68 GB):  28%|██▊       | 10/36 [00:00<00:01, 20.64it/s]Capturing batches (bs=168 avail_mem=33.68 GB):  28%|██▊       | 10/36 [00:00<00:01, 20.64it/s]Capturing batches (bs=160 avail_mem=33.67 GB):  28%|██▊       | 10/36 [00:00<00:01, 20.64it/s]Capturing batches (bs=160 avail_mem=33.67 GB):  36%|███▌      | 13/36 [00:00<00:01, 20.89it/s]Capturing batches (bs=152 avail_mem=33.66 GB):  36%|███▌      | 13/36 [00:00<00:01, 20.89it/s]Capturing batches (bs=144 avail_mem=33.66 GB):  36%|███▌      | 13/36 [00:00<00:01, 20.89it/s]Capturing batches (bs=136 avail_mem=33.65 GB):  36%|███▌      | 13/36 [00:00<00:01, 20.89it/s]Capturing batches (bs=136 avail_mem=33.65 GB):  44%|████▍     | 16/36 [00:00<00:00, 20.89it/s]Capturing batches (bs=128 avail_mem=33.64 GB):  44%|████▍     | 16/36 [00:00<00:00, 20.89it/s]Capturing batches (bs=120 avail_mem=33.63 GB):  44%|████▍     | 16/36 [00:00<00:00, 20.89it/s]Capturing batches (bs=112 avail_mem=33.63 GB):  44%|████▍     | 16/36 [00:00<00:00, 20.89it/s]Capturing batches (bs=112 avail_mem=33.63 GB):  53%|█████▎    | 19/36 [00:00<00:00, 21.42it/s]Capturing batches (bs=104 avail_mem=33.62 GB):  53%|█████▎    | 19/36 [00:00<00:00, 21.42it/s]Capturing batches (bs=96 avail_mem=33.62 GB):  53%|█████▎    | 19/36 [00:00<00:00, 21.42it/s] Capturing batches (bs=88 avail_mem=33.61 GB):  53%|█████▎    | 19/36 [00:01<00:00, 21.42it/s]Capturing batches (bs=88 avail_mem=33.61 GB):  61%|██████    | 22/36 [00:01<00:00, 21.12it/s]Capturing batches (bs=80 avail_mem=33.61 GB):  61%|██████    | 22/36 [00:01<00:00, 21.12it/s]Capturing batches (bs=72 avail_mem=33.60 GB):  61%|██████    | 22/36 [00:01<00:00, 21.12it/s]Capturing batches (bs=64 avail_mem=33.60 GB):  61%|██████    | 22/36 [00:01<00:00, 21.12it/s]Capturing batches (bs=64 avail_mem=33.60 GB):  69%|██████▉   | 25/36 [00:01<00:00, 21.05it/s]Capturing batches (bs=56 avail_mem=33.59 GB):  69%|██████▉   | 25/36 [00:01<00:00, 21.05it/s]Capturing batches (bs=48 avail_mem=33.59 GB):  69%|██████▉   | 25/36 [00:01<00:00, 21.05it/s]Capturing batches (bs=40 avail_mem=33.58 GB):  69%|██████▉   | 25/36 [00:01<00:00, 21.05it/s]Capturing batches (bs=40 avail_mem=33.58 GB):  78%|███████▊  | 28/36 [00:01<00:00, 21.57it/s]Capturing batches (bs=32 avail_mem=33.58 GB):  78%|███████▊  | 28/36 [00:01<00:00, 21.57it/s]Capturing batches (bs=24 avail_mem=33.57 GB):  78%|███████▊  | 28/36 [00:01<00:00, 21.57it/s]Capturing batches (bs=16 avail_mem=33.57 GB):  78%|███████▊  | 28/36 [00:01<00:00, 21.57it/s]Capturing batches (bs=16 avail_mem=33.57 GB):  86%|████████▌ | 31/36 [00:01<00:00, 20.23it/s]Capturing batches (bs=12 avail_mem=33.56 GB):  86%|████████▌ | 31/36 [00:01<00:00, 20.23it/s]Capturing batches (bs=8 avail_mem=33.56 GB):  86%|████████▌ | 31/36 [00:01<00:00, 20.23it/s] Capturing batches (bs=4 avail_mem=33.55 GB):  86%|████████▌ | 31/36 [00:01<00:00, 20.23it/s]Capturing batches (bs=4 avail_mem=33.55 GB):  94%|█████████▍| 34/36 [00:01<00:00, 21.45it/s]Capturing batches (bs=2 avail_mem=33.55 GB):  94%|█████████▍| 34/36 [00:01<00:00, 21.45it/s]Capturing batches (bs=1 avail_mem=33.54 GB):  94%|█████████▍| 34/36 [00:01<00:00, 21.45it/s]Capturing batches (bs=1 avail_mem=33.54 GB): 100%|██████████| 36/36 [00:01<00:00, 21.02it/s]
0, 131709 MiB
1, 4 MiB
2, 4 MiB
3, 108874 MiB
✓ 模型加载完成！耗时: 42.39秒

[GPU使用检查]

[4/5] 开始强制generate多轮对话测试...
⚠️  测试 50 条轨迹

生成 10 轮对话...

======================================================================
测试 Batch Size: 1, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 5/50 (10.0%), 速度: 1119.74 条/秒, 已用时: 0.0秒
  进度: 10/50 (20.0%), 速度: 1108.64 条/秒, 已用时: 0.0秒
  进度: 15/50 (30.0%), 速度: 1135.21 条/秒, 已用时: 0.0秒
  进度: 20/50 (40.0%), 速度: 1111.78 条/秒, 已用时: 0.0秒
  进度: 25/50 (50.0%), 速度: 1133.56 条/秒, 已用时: 0.0秒
  进度: 30/50 (60.0%), 速度: 1147.96 条/秒, 已用时: 0.0秒
  进度: 35/50 (70.0%), 速度: 1162.08 条/秒, 已用时: 0.0秒
  进度: 40/50 (80.0%), 速度: 1167.90 条/秒, 已用时: 0.0秒
  进度: 45/50 (90.0%), 速度: 1176.93 条/秒, 已用时: 0.0秒
  进度: 50/50 (100.0%), 速度: 1174.72 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 1, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1174.58 条/秒
  每条轨迹平均推理耗时: 0.0009 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 2, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 10/50 (20.0%), 速度: 1284.67 条/秒, 已用时: 0.0秒
  进度: 20/50 (40.0%), 速度: 1312.63 条/秒, 已用时: 0.0秒
  进度: 30/50 (60.0%), 速度: 1291.26 条/秒, 已用时: 0.0秒
  进度: 40/50 (80.0%), 速度: 1304.37 条/秒, 已用时: 0.0秒
  进度: 50/50 (100.0%), 速度: 1224.43 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 2, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1224.16 条/秒
  每条轨迹平均推理耗时: 0.0008 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 4, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 20/50 (40.0%), 速度: 1185.84 条/秒, 已用时: 0.0秒
  进度: 40/50 (80.0%), 速度: 1203.84 条/秒, 已用时: 0.0秒
  进度: 50/50 (100.0%), 速度: 1200.37 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 4, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1200.19 条/秒
  每条轨迹平均推理耗时: 0.0008 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 8, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 40/50 (80.0%), 速度: 1224.69 条/秒, 已用时: 0.0秒
  进度: 50/50 (100.0%), 速度: 1261.06 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 8, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1260.84 条/秒
  每条轨迹平均推理耗时: 0.0008 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 16, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 50/50 (100.0%), 速度: 1221.69 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 16, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1221.40 条/秒
  每条轨迹平均推理耗时: 0.0008 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 32, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 50/50 (100.0%), 速度: 1211.48 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 32, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1211.23 条/秒
  每条轨迹平均推理耗时: 0.0008 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 64, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 50/50 (100.0%), 速度: 1206.88 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 64, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1206.56 条/秒
  每条轨迹平均推理耗时: 0.0008 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 128, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 50/50 (100.0%), 速度: 200.08 条/秒, 已用时: 0.2秒

======================================================================
Batch Size 128, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.25 秒
  平均速度: 200.07 条/秒
  每条轨迹平均推理耗时: 0.0050 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.25 秒
  平均生成时间/轨迹: 0.0050 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


======================================================================
测试 Batch Size: 256, 生成轮数: 10
======================================================================
准备了 50 条轨迹
平均每条生成 10.0 轮assistant回复
原始assistant消息平均长度: 4197 字符/轨迹
平均环境执行时间: 3.5185秒/轨迹
  进度: 50/50 (100.0%), 速度: 1187.24 条/秒, 已用时: 0.0秒

======================================================================
Batch Size 256, 10轮对话 测试结果:
  总轨迹数: 50
  成功处理: 50
  失败: 0
  推理总耗时: 0.04 秒
  平均速度: 1186.97 条/秒
  每条轨迹平均推理耗时: 0.0008 秒
  生成token总数: 0
  平均tokens/轨迹: 0.0
  每轮平均tokens: 0.0
  总生成时间: 0.04 秒
  平均生成时间/轨迹: 0.0008 秒
  
  环境执行时间统计（来自原始数据）:
    平均env执行时间: 3.5185 秒/轨迹
    总env执行时间: 175.93 秒
======================================================================


[5/5] 性能测试汇总
======================================================================
轨迹数量: 50 条
生成轮数: 10 轮
======================================================================
Batch    总耗时          吞吐量            每条耗时           平均Tokens      
Size     (秒)          (条/秒)          (秒)            (/轨迹)         
----------------------------------------------------------------------
1        0.04         1174.58        0.00           0.0           
2        0.04         1224.16        0.00           0.0           
4        0.04         1200.19        0.00           0.0           
8        0.04         1260.84        0.00           0.0           
16       0.04         1221.40        0.00           0.0           
32       0.04         1211.23        0.00           0.0           
64       0.04         1206.56        0.00           0.0           
128      0.25         200.07         0.00           0.0           
256      0.04         1186.97        0.00           0.0           
======================================================================

最优配置:
  Batch Size = 8
  吞吐量 = 1260.84 条/秒
  完成50条轨迹需要: 0.04 秒
  平均生成 0.0 tokens/轨迹

完成50条10轮对话所需时间对比:
----------------------------------------------------------------------
  Batch Size   8:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size   2:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size  16:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size  32:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size  64:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size   4:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size 256:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size   1:     0.04 秒 (成功: 100%, 0 tokens/轨迹)
  Batch Size 128:     0.25 秒 (成功: 100%, 0 tokens/轨迹)
----------------------------------------------------------------------

结果已保存到: benchmark_results_force_generate_50traj_10turns.json

清理资源...
✓ 所有测试完成！
结束时间: 2025-11-25 08:42:43
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py:410: UserWarning: Error in stream_executor: Traceback (most recent call last):
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 408, in _thread_worker_func
    self._execute(expr)
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 451, in _execute
    self._execute(x)
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 446, in _execute
    self._execute_gen(other)
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 574, in _execute_gen
    comp, meta_info = self.backend.generate(
                      ^^^^^^^^^^^^^^^^^^^^^^
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/backend/runtime_endpoint.py", line 185, in generate
    res = http_request(
          ^^^^^^^^^^^^^
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/utils.py", line 170, in http_request
    resp = urllib.request.urlopen(req, data=data, cafile=verify)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 519, in open
    response = self._open(req, data)
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 536, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 496, in _call_chain
    result = func(*args)
             ^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 1377, in http_open
    return self.do_open(http.client.HTTPConnection, req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 1352, in do_open
    r = h.getresponse()
        ^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

  warnings.warn(f"Error in stream_executor: {get_exception_traceback()}")
/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py:410: UserWarning: Error in stream_executor: Traceback (most recent call last):
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 408, in _thread_worker_func
    self._execute(expr)
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 451, in _execute
    self._execute(x)
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 446, in _execute
    self._execute_gen(other)
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/interpreter.py", line 574, in _execute_gen
    comp, meta_info = self.backend.generate(
                      ^^^^^^^^^^^^^^^^^^^^^^
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/lang/backend/runtime_endpoint.py", line 185, in generate
    res = http_request(
          ^^^^^^^^^^^^^
  File "/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/.venv/lib/python3.11/site-packages/sglang/utils.py", line 170, in http_request
    resp = urllib.request.urlopen(req, data=data, cafile=verify)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 519, in open
    response = self._open(req, data)
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 536, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 496, in _call_chain
    result = func(*args)
             ^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 1377, in http_open
    return self.do_open(http.client.HTTPConnection, req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/urllib/request.py", line 1352, in do_open
    r = h.getresponse()
        ^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/socket.py", line 718, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

  warnings.warn(f"Error in stream_executor: {get_exception_traceback()}")
/home/ruobai/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
