# SGLang 批量推理性能测试报告

## 测试概况

- **测试时间**: 2025-11-25 08:24:51
- **模型路径**: `/data/minimax-dialogue/users/ruobai/cogito/base_model/R2EGym-7B-Agent`
- **GPU设备**: GPU 3
- **轨迹数量**: 500条
- **数据来源**: `/data/minimax-dialogue/users/ruobai/cogito_dev/course_project_854/20250826_070310_MULTI_xiancai-80_swe_verified_train_0_5000.jsonl`
- **配置文件**: `/data/minimax-dialogue/users/ruobai/r2e-gym-xiancai/src/r2egym/agenthub/config/r2egym/edit_non_fn_calling_.yaml`

## 模型加载

- **加载时间**: 46.33秒

## 测试结果汇总

### 不同Batch Size性能对比

| Batch Size | 完成500条时间 | 吞吐量(条/秒) | 每条耗时(秒) | 性能排名 |
|-----------|-------------|-------------|------------|---------|
| 2         | **0.31秒**   | **1594.20** | 0.0006     | 🥇 第1   |
| 4         | 0.33秒      | 1526.72     | 0.0007     | 🥈 第2   |
| 8         | 0.33秒      | 1502.99     | 0.0007     | 🥉 第3   |
| 1         | 0.55秒      | 909.87      | 0.0011     | 第4     |
| 16        | 0.56秒      | 891.79      | 0.0011     | 第5     |

### 关键发现

1. **最优配置**: Batch Size = 2
   - 吞吐量最高: 1594.20 条/秒
   - 完成500条轨迹仅需: **0.31秒**
   - 相比Batch Size=1提升: 75.2%

2. **性能趋势**:
   - Batch Size从1增加到2时，性能提升显著（75.2%）
   - Batch Size为2-8时，性能相对稳定（1503-1594条/秒）
   - Batch Size继续增加到16时，性能反而下降

3. **推荐使用**: Batch Size = 2或4
   - 两者性能接近，都能在0.3-0.33秒内完成500条轨迹
   - Batch Size=2略优，但差异不大

## 环境执行时间统计

从原始数据中提取的环境执行时间（env_exec_time）：

- **平均环境执行时间**: 2.1492秒/轨迹
- **500条总环境时间**: 1074.60秒（约17.9分钟）

这是原始数据中记录的环境执行时间，表示每条轨迹在实际环境中运行所需的时间。

## 详细测试结果

### Batch Size = 1
```
总耗时: 0.55秒
吞吐量: 909.87 条/秒
每条耗时: 0.0011秒
成功率: 100% (500/500)
```

### Batch Size = 2 (最优)
```
总耗时: 0.31秒 ⭐
吞吐量: 1594.20 条/秒 ⭐
每条耗时: 0.0006秒
成功率: 100% (500/500)
```

### Batch Size = 4
```
总耗时: 0.33秒
吞吐量: 1526.72 条/秒
每条耗时: 0.0007秒
成功率: 100% (500/500)
```

### Batch Size = 8
```
总耗时: 0.33秒
吞吐量: 1502.99 条/秒
每条耗时: 0.0007秒
成功率: 100% (500/500)
```

### Batch Size = 16
```
总耗时: 0.56秒
吞吐量: 891.79 条/秒
每条耗时: 0.0011秒
成功率: 100% (500/500)
```

## 结论

1. **使用Batch Size=2可以实现最佳性能**
   - 完成500条轨迹仅需0.31秒
   - 吞吐量达到1594条/秒

2. **所有测试配置成功率均为100%**
   - 没有失败案例
   - 系统稳定可靠

3. **性能瓶颈分析**
   - Batch Size过小(=1): 未充分利用GPU并行能力
   - Batch Size过大(=16): 可能受到内存带宽或调度开销影响

4. **实际应用建议**
   - 推荐使用Batch Size=2或4
   - 如需处理大量轨迹，使用Batch Size=2可获得最佳吞吐量
   - 实际部署时可根据GPU显存和延迟要求调整

## 数据说明

- 本测试使用简化的推理方式（不生成新token），主要测量处理多轮对话上下文的能力
- 每条轨迹包含System prompt + User prompt（包含problem_statement）
- 原始数据中包含完整的多轮对话历史（thought, action, observation, env_exec_time等）
- 测试成功展示了SGLang在批量处理多轮对话场景中的高效性能

## 文件清单

- `benchmark_results_500_stable.json` - 详细的JSON格式测试结果
- `benchmark_stable_output.log` - 完整的测试日志
- `batch_benchmark_stable.py` - 测试脚本源代码

